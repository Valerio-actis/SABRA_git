{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b66ab32",
   "metadata": {},
   "source": [
    "### RBM learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2c8ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from directory: /home/vale/SABRA/params_bin/sim_nn10_LAM_2_nu1e8/Spectra_complex\n",
      "Found 10000 snapshot files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 10000/10000 [00:09<00:00, 1047.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 snapshots with 10 shells each.\n",
      "scalers: (StandardScaler(), StandardScaler())\n",
      "Initializing RBM with 20 visible units and 10 hidden units\n",
      "Training RBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 100/100 [00:00<00:00, 387.47it/s]\n",
      "Epoch 2/200: 100%|██████████| 100/100 [00:00<00:00, 556.29it/s]\n",
      "Epoch 3/200: 100%|██████████| 100/100 [00:00<00:00, 476.00it/s]\n",
      "Epoch 4/200: 100%|██████████| 100/100 [00:00<00:00, 486.83it/s]\n",
      "Epoch 5/200: 100%|██████████| 100/100 [00:00<00:00, 391.19it/s]\n",
      "Epoch 6/200: 100%|██████████| 100/100 [00:00<00:00, 518.62it/s]\n",
      "Epoch 7/200: 100%|██████████| 100/100 [00:00<00:00, 574.71it/s]\n",
      "Epoch 8/200: 100%|██████████| 100/100 [00:00<00:00, 503.97it/s]\n",
      "Epoch 9/200: 100%|██████████| 100/100 [00:00<00:00, 536.83it/s]\n",
      "Epoch 10/200: 100%|██████████| 100/100 [00:00<00:00, 548.57it/s]\n",
      "Epoch 11/200: 100%|██████████| 100/100 [00:00<00:00, 431.09it/s]\n",
      "Epoch 12/200: 100%|██████████| 100/100 [00:00<00:00, 433.26it/s]\n",
      "Epoch 13/200: 100%|██████████| 100/100 [00:00<00:00, 566.49it/s]\n",
      "Epoch 14/200: 100%|██████████| 100/100 [00:00<00:00, 520.58it/s]\n",
      "Epoch 15/200: 100%|██████████| 100/100 [00:00<00:00, 486.64it/s]\n",
      "Epoch 16/200: 100%|██████████| 100/100 [00:00<00:00, 554.14it/s]\n",
      "Epoch 17/200: 100%|██████████| 100/100 [00:00<00:00, 427.53it/s]\n",
      "Epoch 18/200: 100%|██████████| 100/100 [00:00<00:00, 541.84it/s]\n",
      "Epoch 19/200: 100%|██████████| 100/100 [00:00<00:00, 547.93it/s]\n",
      "Epoch 20/200: 100%|██████████| 100/100 [00:00<00:00, 606.71it/s]\n",
      "Epoch 21/200: 100%|██████████| 100/100 [00:00<00:00, 491.13it/s]\n",
      "Epoch 22/200: 100%|██████████| 100/100 [00:00<00:00, 604.24it/s]\n",
      "Epoch 23/200: 100%|██████████| 100/100 [00:00<00:00, 365.90it/s]\n",
      "Epoch 24/200: 100%|██████████| 100/100 [00:00<00:00, 267.37it/s]\n",
      "Epoch 25/200: 100%|██████████| 100/100 [00:00<00:00, 354.00it/s]\n",
      "Epoch 26/200: 100%|██████████| 100/100 [00:00<00:00, 405.03it/s]\n",
      "Epoch 27/200: 100%|██████████| 100/100 [00:00<00:00, 386.50it/s]\n",
      "Epoch 28/200: 100%|██████████| 100/100 [00:00<00:00, 227.02it/s]\n",
      "Epoch 29/200: 100%|██████████| 100/100 [00:00<00:00, 504.01it/s]\n",
      "Epoch 30/200: 100%|██████████| 100/100 [00:00<00:00, 524.69it/s]\n",
      "Epoch 31/200: 100%|██████████| 100/100 [00:00<00:00, 489.84it/s]\n",
      "Epoch 32/200: 100%|██████████| 100/100 [00:00<00:00, 485.30it/s]\n",
      "Epoch 33/200: 100%|██████████| 100/100 [00:00<00:00, 383.79it/s]\n",
      "Epoch 34/200: 100%|██████████| 100/100 [00:00<00:00, 503.30it/s]\n",
      "Epoch 35/200: 100%|██████████| 100/100 [00:00<00:00, 573.77it/s]\n",
      "Epoch 36/200: 100%|██████████| 100/100 [00:00<00:00, 534.25it/s]\n",
      "Epoch 37/200: 100%|██████████| 100/100 [00:00<00:00, 485.20it/s]\n",
      "Epoch 38/200: 100%|██████████| 100/100 [00:00<00:00, 515.38it/s]\n",
      "Epoch 39/200: 100%|██████████| 100/100 [00:00<00:00, 428.40it/s]\n",
      "Epoch 40/200: 100%|██████████| 100/100 [00:00<00:00, 480.49it/s]\n",
      "Epoch 41/200: 100%|██████████| 100/100 [00:00<00:00, 559.31it/s]\n",
      "Epoch 42/200: 100%|██████████| 100/100 [00:00<00:00, 530.84it/s]\n",
      "Epoch 43/200: 100%|██████████| 100/100 [00:00<00:00, 495.37it/s]\n",
      "Epoch 44/200: 100%|██████████| 100/100 [00:00<00:00, 459.65it/s]\n",
      "Epoch 45/200: 100%|██████████| 100/100 [00:00<00:00, 458.75it/s]\n",
      "Epoch 46/200: 100%|██████████| 100/100 [00:00<00:00, 442.37it/s]\n",
      "Epoch 47/200: 100%|██████████| 100/100 [00:00<00:00, 414.24it/s]\n",
      "Epoch 48/200: 100%|██████████| 100/100 [00:00<00:00, 361.03it/s]\n",
      "Epoch 49/200: 100%|██████████| 100/100 [00:00<00:00, -103.72it/s]\n",
      "Epoch 50/200: 100%|██████████| 100/100 [00:00<00:00, 498.89it/s]\n",
      "Epoch 51/200: 100%|██████████| 100/100 [00:00<00:00, 552.85it/s]\n",
      "Epoch 52/200: 100%|██████████| 100/100 [00:00<00:00, 565.82it/s]\n",
      "Epoch 53/200: 100%|██████████| 100/100 [00:00<00:00, 342.91it/s]\n",
      "Epoch 54/200: 100%|██████████| 100/100 [00:00<00:00, 529.59it/s]\n",
      "Epoch 55/200: 100%|██████████| 100/100 [00:00<00:00, 541.57it/s]\n",
      "Epoch 56/200: 100%|██████████| 100/100 [00:00<00:00, 457.70it/s]\n",
      "Epoch 57/200: 100%|██████████| 100/100 [00:00<00:00, 518.69it/s]\n",
      "Epoch 58/200: 100%|██████████| 100/100 [00:00<00:00, 572.60it/s]\n",
      "Epoch 59/200: 100%|██████████| 100/100 [00:00<00:00, 415.07it/s]\n",
      "Epoch 60/200: 100%|██████████| 100/100 [00:00<00:00, 588.03it/s]\n",
      "Epoch 61/200: 100%|██████████| 100/100 [00:00<00:00, 592.24it/s]\n",
      "Epoch 62/200: 100%|██████████| 100/100 [00:00<00:00, 510.64it/s]\n",
      "Epoch 63/200: 100%|██████████| 100/100 [00:00<00:00, 397.18it/s]\n",
      "Epoch 64/200: 100%|██████████| 100/100 [00:00<00:00, 527.11it/s]\n",
      "Epoch 65/200: 100%|██████████| 100/100 [00:00<00:00, 584.05it/s]\n",
      "Epoch 66/200: 100%|██████████| 100/100 [00:00<00:00, 453.99it/s]\n",
      "Epoch 67/200: 100%|██████████| 100/100 [00:00<00:00, 612.95it/s]\n",
      "Epoch 68/200: 100%|██████████| 100/100 [00:00<00:00, 452.64it/s]\n",
      "Epoch 69/200: 100%|██████████| 100/100 [00:00<00:00, 448.72it/s]\n",
      "Epoch 70/200: 100%|██████████| 100/100 [00:00<00:00, 522.10it/s]\n",
      "Epoch 71/200: 100%|██████████| 100/100 [00:00<00:00, 578.52it/s]\n",
      "Epoch 72/200: 100%|██████████| 100/100 [00:00<00:00, 542.69it/s]\n",
      "Epoch 73/200: 100%|██████████| 100/100 [00:00<00:00, 451.82it/s]\n",
      "Epoch 74/200: 100%|██████████| 100/100 [00:00<00:00, 523.74it/s]\n",
      "Epoch 75/200: 100%|██████████| 100/100 [00:00<00:00, 465.98it/s]\n",
      "Epoch 76/200: 100%|██████████| 100/100 [00:00<00:00, 573.91it/s]\n",
      "Epoch 77/200: 100%|██████████| 100/100 [00:00<00:00, 535.05it/s]\n",
      "Epoch 78/200: 100%|██████████| 100/100 [00:00<00:00, 516.18it/s]\n",
      "Epoch 79/200: 100%|██████████| 100/100 [00:00<00:00, 480.55it/s]\n",
      "Epoch 80/200: 100%|██████████| 100/100 [00:00<00:00, 451.46it/s]\n",
      "Epoch 81/200: 100%|██████████| 100/100 [00:00<00:00, 389.89it/s]\n",
      "Epoch 82/200: 100%|██████████| 100/100 [00:00<00:00, 536.62it/s]\n",
      "Epoch 83/200: 100%|██████████| 100/100 [00:00<00:00, 551.15it/s]\n",
      "Epoch 84/200: 100%|██████████| 100/100 [00:00<00:00, 423.49it/s]\n",
      "Epoch 85/200: 100%|██████████| 100/100 [00:00<00:00, 535.98it/s]\n",
      "Epoch 86/200: 100%|██████████| 100/100 [00:00<00:00, 574.08it/s]\n",
      "Epoch 87/200: 100%|██████████| 100/100 [00:00<00:00, 392.06it/s]\n",
      "Epoch 88/200: 100%|██████████| 100/100 [00:00<00:00, 543.05it/s]\n",
      "Epoch 89/200: 100%|██████████| 100/100 [00:00<00:00, 489.41it/s]\n",
      "Epoch 90/200: 100%|██████████| 100/100 [00:00<00:00, 505.65it/s]\n",
      "Epoch 91/200: 100%|██████████| 100/100 [00:00<00:00, 486.00it/s]\n",
      "Epoch 92/200: 100%|██████████| 100/100 [00:00<00:00, 450.42it/s]\n",
      "Epoch 93/200: 100%|██████████| 100/100 [00:00<00:00, 419.26it/s]\n",
      "Epoch 94/200: 100%|██████████| 100/100 [00:00<00:00, 445.38it/s]\n",
      "Epoch 95/200: 100%|██████████| 100/100 [00:00<00:00, 379.69it/s]\n",
      "Epoch 96/200: 100%|██████████| 100/100 [00:00<00:00, 562.94it/s]\n",
      "Epoch 97/200: 100%|██████████| 100/100 [00:00<00:00, 524.15it/s]\n",
      "Epoch 98/200: 100%|██████████| 100/100 [00:00<00:00, 389.30it/s]\n",
      "Epoch 99/200: 100%|██████████| 100/100 [00:00<00:00, 420.54it/s]\n",
      "Epoch 100/200: 100%|██████████| 100/100 [00:00<00:00, 506.56it/s]\n",
      "Epoch 101/200: 100%|██████████| 100/100 [00:00<00:00, 559.71it/s]\n",
      "Epoch 102/200: 100%|██████████| 100/100 [00:00<00:00, 516.96it/s]\n",
      "Epoch 103/200:  57%|█████▋    | 57/100 [00:00<00:00, 489.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 581\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalysis complete. Results saved to disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 581\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 553\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining RBM...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m#rbm.load_state_dict(torch.load(\"trained_rbm.pt\"))\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m rbm \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_rbm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# Save trained model\u001b[39;00m\n\u001b[1;32m    556\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRBMs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 336\u001b[0m, in \u001b[0;36mtrain_rbm\u001b[0;34m(rbm, train_data, batch_size, num_epochs, early_stopping, patience, min_improvement, k, normalize)\u001b[0m\n\u001b[1;32m    333\u001b[0m epoch_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    334\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data,) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    337\u001b[0m     error \u001b[38;5;241m=\u001b[39m rbm\u001b[38;5;241m.\u001b[39mtrain_batch(data)\n\u001b[1;32m    338\u001b[0m     epoch_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m error\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataset.py:207\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataset.py:207\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from io import StringIO\n",
    "\n",
    "USE_TORCH = True\n",
    "\n",
    "\n",
    "class ComplexRBM(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of RBM for learning shell interactions in complex-valued data.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_visible, n_hidden, k=1, learning_rate=0.01, momentum=0.5, weight_decay=1e-4):\n",
    "        \"\"\"\n",
    "        Initialize the RBM.\n",
    "        \n",
    "        Args:\n",
    "            n_visible: Number of visible units (2 * number of shells for complex data)\n",
    "            n_hidden: Number of hidden units\n",
    "            k: Number of Gibbs sampling steps (typically 1)\n",
    "            learning_rate: Learning rate for gradient descent\n",
    "            momentum: Momentum factor for gradient descent\n",
    "            weight_decay: L2 regularization factor\n",
    "        \"\"\"\n",
    "        super(ComplexRBM, self).__init__()\n",
    "        \n",
    "        # Model parameters\n",
    "        self.W = nn.Parameter(torch.randn(n_visible, n_hidden) * 0.01)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_visible))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hidden))\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # For monitoring\n",
    "        self.reconstruction_error_history = []\n",
    "        \n",
    "        # For momentum updates\n",
    "        self.W_momentum = torch.zeros_like(self.W)\n",
    "        self.v_bias_momentum = torch.zeros_like(self.v_bias)\n",
    "        self.h_bias_momentum = torch.zeros_like(self.h_bias)\n",
    "    \n",
    "    def sample_h_given_v(self, v):\n",
    "        \"\"\"Sample hidden units given visible units.\"\"\"\n",
    "        h_prob = torch.sigmoid(torch.matmul(v, self.W) + self.h_bias)\n",
    "        h_sample = torch.bernoulli(h_prob)\n",
    "        return h_prob, h_sample\n",
    "    \n",
    "    def sample_v_given_h(self, h):\n",
    "        \"\"\"Sample visible units given hidden units.\"\"\"\n",
    "        v_prob = torch.sigmoid(torch.matmul(h, self.W.t()) + self.v_bias)\n",
    "        v_sample = torch.bernoulli(v_prob)\n",
    "        return v_prob, v_sample\n",
    "    \n",
    "    def free_energy(self, v):\n",
    "        \"\"\"Calculate the free energy.\"\"\"\n",
    "        v_bias_term = torch.matmul(v, self.v_bias)\n",
    "        hidden_term = torch.sum(torch.log(1 + torch.exp(torch.matmul(v, self.W) + self.h_bias)), dim=1)\n",
    "        return -v_bias_term - hidden_term\n",
    "    \n",
    "    def forward(self, v):\n",
    "        \"\"\"Forward pass: reconstruct v.\"\"\"\n",
    "        h_prob, h_sample = self.sample_h_given_v(v)\n",
    "        v_prob, _ = self.sample_v_given_h(h_sample)\n",
    "        return v_prob\n",
    "    \n",
    "    def contrastive_divergence(self, v_data, k=1):\n",
    "        \"\"\"Perform contrastive divergence-k training step.\"\"\"\n",
    "        # Positive phase\n",
    "        h_prob, h_sample = self.sample_h_given_v(v_data)\n",
    "        pos_associations = torch.matmul(v_data.t(), h_prob)\n",
    "        \n",
    "        # Negative phase (Gibbs sampling)\n",
    "        v_sample = v_data.clone()\n",
    "        for _ in range(k):\n",
    "            _, h_sample = self.sample_h_given_v(v_sample)\n",
    "            v_prob, v_sample = self.sample_v_given_h(h_sample)\n",
    "        \n",
    "        h_prob_neg, _ = self.sample_h_given_v(v_sample)\n",
    "        neg_associations = torch.matmul(v_sample.t(), h_prob_neg)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        batch_size = v_data.size(0)\n",
    "        \n",
    "        W_grad = (pos_associations - neg_associations) / batch_size\n",
    "        v_bias_grad = torch.mean(v_data - v_sample, dim=0)\n",
    "        h_bias_grad = torch.mean(h_prob - h_prob_neg, dim=0)  # Fixed bug here\n",
    "        \n",
    "        # L2 weight decay\n",
    "        W_grad -= self.weight_decay * self.W\n",
    "        \n",
    "        return W_grad, v_bias_grad, h_bias_grad, v_sample\n",
    "    \n",
    "    def train_batch(self, v_data, optimizer=None):\n",
    "        \"\"\"Train on a batch of data.\"\"\"\n",
    "        W_grad, v_bias_grad, h_bias_grad, v_recon = self.contrastive_divergence(v_data, self.k)\n",
    "        \n",
    "        # Apply momentum updates\n",
    "        with torch.no_grad():\n",
    "            self.W_momentum = self.momentum * self.W_momentum + self.learning_rate * W_grad\n",
    "            self.v_bias_momentum = self.momentum * self.v_bias_momentum + self.learning_rate * v_bias_grad\n",
    "            self.h_bias_momentum = self.momentum * self.h_bias_momentum + self.learning_rate * h_bias_grad\n",
    "            \n",
    "            self.W += self.W_momentum\n",
    "            self.v_bias += self.v_bias_momentum\n",
    "            self.h_bias += self.h_bias_momentum\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        reconstruction_error = torch.mean(torch.sum((v_data - v_recon) ** 2, dim=1))\n",
    "        self.reconstruction_error_history.append(reconstruction_error.item())\n",
    "        \n",
    "        return reconstruction_error.item()\n",
    "    \n",
    "    def generate_samples(self, n_samples, initial_v=None, k_steps=1000):\n",
    "        \"\"\"Generate samples from the model.\"\"\"\n",
    "        if initial_v is None:\n",
    "            initial_v = torch.rand(n_samples, self.v_bias.size(0))\n",
    "        \n",
    "        v_samples = initial_v.clone()\n",
    "        \n",
    "        # Run Gibbs sampling for k_steps\n",
    "        for _ in range(k_steps):\n",
    "            _, h_samples = self.sample_h_given_v(v_samples)\n",
    "            v_prob, v_samples = self.sample_v_given_h(h_samples)\n",
    "        \n",
    "        return v_samples\n",
    "    \n",
    "    def shell_interaction_strength(self):\n",
    "        \"\"\"\n",
    "        Analyze the weight matrix to determine shell interaction strengths.\n",
    "        Returns a matrix where element (i,j) represents the strength of \n",
    "        interaction between shell i and shell j.\n",
    "        \"\"\"\n",
    "        n_shells = self.W.shape[0] // 2  # Divide by 2 because we have real and imaginary parts\n",
    "        interaction_matrix = torch.zeros((n_shells, n_shells))\n",
    "        \n",
    "        # For each pair of shells, compute the average absolute connection strength\n",
    "        for i in range(n_shells):\n",
    "            for j in range(n_shells):\n",
    "                # Get weights connecting shell i (real and imag) to all hidden units\n",
    "                shell_i_real_weights = self.W[2*i, :]\n",
    "                shell_i_imag_weights = self.W[2*i+1, :]\n",
    "                \n",
    "                # Get weights connecting shell j (real and imag) to all hidden units\n",
    "                shell_j_real_weights = self.W[2*j, :]\n",
    "                shell_j_imag_weights = self.W[2*j+1, :]\n",
    "                \n",
    "                # Compute correlation between weight patterns\n",
    "                corr_real_real = torch.mean(torch.abs(shell_i_real_weights * shell_j_real_weights))\n",
    "                corr_real_imag = torch.mean(torch.abs(shell_i_real_weights * shell_j_imag_weights))\n",
    "                corr_imag_real = torch.mean(torch.abs(shell_i_imag_weights * shell_j_real_weights))\n",
    "                corr_imag_imag = torch.mean(torch.abs(shell_i_imag_weights * shell_j_imag_weights))\n",
    "                \n",
    "                # Average correlation across real/imaginary components\n",
    "                interaction_matrix[i, j] = (corr_real_real + corr_real_imag + \n",
    "                                            corr_imag_real + corr_imag_imag) / 4\n",
    "        \n",
    "        return interaction_matrix\n",
    "\n",
    "\n",
    "def load_complex_data(file_path):\n",
    "    \"\"\"\n",
    "    Load complex spectral data with proper handling for scientific notation and minus signs.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the data file\n",
    "        \n",
    "    Returns:\n",
    "        wavenumbers: Array of wavenumbers (shells)\n",
    "        velocities: Complex array of velocities\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read().strip()\n",
    "        \n",
    "        # Split into lines and process each line\n",
    "        lines = content.split('\\n')\n",
    "        data_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            # Use regex to properly split scientific notation numbers\n",
    "            # This pattern matches scientific notation including negative numbers\n",
    "            pattern = r'([+-]?\\d+\\.?\\d*[eE][+-]?\\d+|[+-]?\\d+\\.?\\d*)'\n",
    "            numbers = re.findall(pattern, line)\n",
    "            \n",
    "            if len(numbers) >= 3:\n",
    "                data_lines.append([float(numbers[0]), float(numbers[1]), float(numbers[2])])\n",
    "            else:\n",
    "                print(f\"Warning: Could not parse line: {line}\")\n",
    "        \n",
    "        if not data_lines:\n",
    "            raise ValueError(\"No valid data lines found\")\n",
    "        \n",
    "        data = np.array(data_lines)\n",
    "        wavenumbers = data[:, 0]\n",
    "        velocities = data[:, 1] + 1j * data[:, 2]\n",
    "        \n",
    "        return wavenumbers, velocities\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_multiple_snapshots(directory, pattern=\"spectr_complex\\..*\\.txt\", max_files=None):\n",
    "    \"\"\"\n",
    "    Load multiple snapshots from a directory matching the given pattern.\n",
    "    \n",
    "    Args:\n",
    "        directory: Directory containing snapshot files\n",
    "        pattern: Regex pattern to match files\n",
    "        max_files: Maximum number of files to load (None for all)\n",
    "        \n",
    "    Returns:\n",
    "        wavenumbers: Array of wavenumbers (shells)\n",
    "        all_velocities: Array of complex velocities [n_snapshots, n_shells]\n",
    "    \"\"\"\n",
    "    # Get list of files matching the pattern\n",
    "    file_pattern = re.compile(pattern)\n",
    "    all_files = [f for f in os.listdir(directory) if file_pattern.match(f)]\n",
    "    all_files.sort()  # Ensure chronological order (lowest to highest, e.g., 1 to 50000)\n",
    "    \n",
    "    if max_files is not None:\n",
    "        all_files = all_files[-max_files:]  # Take the last max_files files (from the end)\n",
    "    \n",
    "    print(f\"Found {len(all_files)} snapshot files.\")\n",
    "    \n",
    "    if not all_files:\n",
    "        raise ValueError(f\"No files found matching pattern {pattern} in directory {directory}\")\n",
    "    \n",
    "    # Load the first file to get dimensions\n",
    "    wavenumbers, _ = load_complex_data(os.path.join(directory, all_files[0]))\n",
    "    n_shells = len(wavenumbers)\n",
    "    \n",
    "    # Initialize array for all velocities\n",
    "    all_velocities = np.zeros((len(all_files), n_shells), dtype=complex)\n",
    "    \n",
    "    # Load data from all files\n",
    "    for i, file_name in enumerate(tqdm(all_files, desc=\"Loading files\")):\n",
    "        try:\n",
    "            _, velocities = load_complex_data(os.path.join(directory, file_name))\n",
    "            if len(velocities) != n_shells:\n",
    "                print(f\"Warning: File {file_name} has {len(velocities)} shells, expected {n_shells}\")\n",
    "                continue\n",
    "            all_velocities[i] = velocities\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return wavenumbers, all_velocities\n",
    "\n",
    "\n",
    "def prepare_data_for_rbm(velocities, normalize=True):\n",
    "    \"\"\"\n",
    "    Prepare complex velocity data for RBM training.\n",
    "    \n",
    "    Args:\n",
    "        velocities: Complex array of shape [n_samples, n_shells]\n",
    "        normalize: Whether to normalize the data\n",
    "        \n",
    "    Returns:\n",
    "        data: PyTorch tensor of shape [n_samples, 2*n_shells]\n",
    "        scalers: Tuple of (scaler_real, scaler_imag) if normalize=True, else None\n",
    "    \"\"\"\n",
    "    # Split complex data into real and imaginary parts\n",
    "    real_parts = np.real(velocities)\n",
    "    imag_parts = np.imag(velocities)\n",
    "    \n",
    "    scalers = None\n",
    "    if normalize:\n",
    "        # Normalize real and imaginary parts separately\n",
    "        scaler_real = StandardScaler()\n",
    "        scaler_imag = StandardScaler()\n",
    "        \n",
    "        real_parts = scaler_real.fit_transform(real_parts)\n",
    "        imag_parts = scaler_imag.fit_transform(imag_parts)\n",
    "        \n",
    "        scalers = (scaler_real, scaler_imag)\n",
    "    \n",
    "    # Interleave real and imaginary parts: [real_1, imag_1, real_2, imag_2, ...]\n",
    "    data = np.zeros((velocities.shape[0], 2 * velocities.shape[1]))\n",
    "    data[:, 0::2] = real_parts\n",
    "    data[:, 1::2] = imag_parts\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    data = torch.tensor(data, dtype=torch.float32)\n",
    "    \n",
    "    return data, scalers\n",
    "\n",
    "\n",
    "def train_rbm(rbm, train_data, batch_size=100, num_epochs=100, early_stopping=False, \n",
    "              patience=10, min_improvement=0.001,k=1,normalize=True):\n",
    "    \"\"\"\n",
    "    Train the RBM on the provided data.\n",
    "    \n",
    "    Args:\n",
    "        rbm: The RBM model\n",
    "        train_data: Training data tensor\n",
    "        batch_size: Batch size for training\n",
    "        num_epochs: Maximum number of training epochs\n",
    "        early_stopping: Whether to use early stopping\n",
    "        patience: Number of epochs with no improvement before stopping\n",
    "        min_improvement: Minimum relative improvement to reset patience counter\n",
    "        \n",
    "    Returns:\n",
    "        rbm: The trained RBM model\n",
    "    \"\"\"\n",
    "    # Create a DataLoader to iterate over the training data in shuffled mini-batches\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(train_data),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    " \n",
    "    best_error = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    epoch_errors = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_error = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (data,) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            error = rbm.train_batch(data)\n",
    "            epoch_error += error\n",
    "            num_batches += 1\n",
    "       \n",
    "        avg_epoch_error = epoch_error / num_batches\n",
    "        epoch_errors.append(avg_epoch_error)\n",
    "        \n",
    "        #print(f\"Epoch {epoch+1}, Reconstruction Error: {avg_epoch_error:.6f}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if early_stopping:\n",
    "            if best_error * (1 - min_improvement) > avg_epoch_error:\n",
    "                best_error = avg_epoch_error\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                \n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Plot training error\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epoch_errors)\n",
    "    plt.title('RBM Training Progress')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Reconstruction Error')\n",
    "    plt.grid(True)\n",
    "    normalization_status = \"normalized\" if normalize else \"not_normalized\"\n",
    "    save_path = \"/home/vale/SABRA/params_bin/RBM_figures\"  # Specify the directory to save the figure\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    plt.savefig(os.path.join(save_path, f\"rbm_training_progress_hidden{rbm.h_bias.shape[0]}_visible{rbm.v_bias.shape[0]}_wd{rbm.weight_decay}_batch{batch_size}_k{rbm.k}_{normalization_status}.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    return rbm\n",
    "\n",
    "\n",
    "def visualize_shell_interactions(rbm, wavenumbers,batch_size=100,k=1):\n",
    "    \"\"\"\n",
    "    Visualize the strength of interactions between shells.\n",
    "    \n",
    "    Args:\n",
    "        rbm: Trained RBM model\n",
    "        wavenumbers: Array of wavenumbers corresponding to each shell\n",
    "    \"\"\"\n",
    "    interaction_matrix = rbm.shell_interaction_strength().detach().numpy()\n",
    "    \n",
    "    # Create log-scale labels for the shells\n",
    "    shell_labels = [f\"{wn:.1e}\" for wn in wavenumbers]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(interaction_matrix, cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar(label='Interaction Strength')\n",
    "    plt.title('Shell Interaction Strength Matrix')\n",
    "    plt.xlabel('Shell Wavenumber')\n",
    "    plt.ylabel('Shell Wavenumber')\n",
    "    plt.xticks(np.arange(len(wavenumbers)), shell_labels, rotation=45)\n",
    "    plt.yticks(np.arange(len(wavenumbers)), shell_labels)\n",
    "    plt.tight_layout()\n",
    "    save_path = \"/home/vale/SABRA/params_bin/RBM_figures\"  # Specify the directory to save the figure\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    plt.savefig(os.path.join(save_path, f\"shell_interaction_matrix_hidden{rbm.h_bias.shape[0]}_visible{rbm.v_bias.shape[0]}_batch{batch_size}_wd{rbm.weight_decay}_k{rbm.k}.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot the diagonal strength (self-interaction) and interaction with neighbors\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.log10(wavenumbers), np.diag(interaction_matrix), 'o-')\n",
    "    plt.title('Self-Interaction Strength')\n",
    "    plt.xlabel('log10(Wavenumber)')\n",
    "    plt.ylabel('Interaction Strength')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Plot interaction with +1 neighbor where available\n",
    "    neighbor_interactions = [interaction_matrix[i, i+1] for i in range(len(wavenumbers)-1)]\n",
    "    plt.plot(np.log10(wavenumbers[:-1]), neighbor_interactions, 'o-', label='+1 Neighbor')\n",
    "    \n",
    "    # Plot interaction with +2 neighbor where available (for triadic interactions)\n",
    "    if len(wavenumbers) > 2:\n",
    "        triadic_interactions = [interaction_matrix[i, i+2] for i in range(len(wavenumbers)-2)]\n",
    "        plt.plot(np.log10(wavenumbers[:-2]), triadic_interactions, 'o-', label='+2 Neighbor')\n",
    "    \n",
    "    plt.title('Neighbor Interaction Strength')\n",
    "    plt.xlabel('log10(Wavenumber)')\n",
    "    plt.ylabel('Interaction Strength')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = \"/home/vale/SABRA/params_bin/RBM_figures\"  # Specify the directory to save the figure\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    plt.savefig(os.path.join(save_path, f\"shell_neighbor_interactions_hidden{rbm.h_bias.shape[0]}_epochs{rbm.reconstruction_error_history.__len__()}.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Also save the interaction matrix as a numpy array for further analysis\n",
    "    np.save(\"shell_interaction_matrix.npy\", interaction_matrix)\n",
    "\n",
    "\n",
    "def analyze_generated_samples(rbm, real_data, wavenumbers, n_samples=1000,batch_size=100,k=1):\n",
    "    \"\"\"\n",
    "    Generate samples from the RBM and compare their statistics with real data.\n",
    "    \n",
    "    Args:\n",
    "        rbm: Trained RBM model\n",
    "        real_data: Real data tensor used for training\n",
    "        wavenumbers: Array of wavenumbers\n",
    "        n_samples: Number of samples to generate\n",
    "    \"\"\"\n",
    "    # Generate samples\n",
    "    n_samples = min(n_samples, real_data.shape[0])  # Don't exceed available data\n",
    "    generated_samples = rbm.generate_samples(n_samples, initial_v=real_data[:n_samples]).detach().numpy()\n",
    "    real_data_np = real_data.numpy()\n",
    "    \n",
    "    # Convert back to complex form\n",
    "    n_shells = len(wavenumbers)\n",
    "    \n",
    "    real_complex = np.zeros((real_data_np.shape[0], n_shells), dtype=complex)\n",
    "    gen_complex = np.zeros((n_samples, n_shells), dtype=complex)\n",
    "    \n",
    "    # Extract real and imaginary parts\n",
    "    for i in range(n_shells):\n",
    "        real_complex[:, i] = real_data_np[:, 2*i] + 1j * real_data_np[:, 2*i+1]\n",
    "        gen_complex[:, i] = generated_samples[:, 2*i] + 1j * generated_samples[:, 2*i+1]\n",
    "    \n",
    "    # Compare energy spectrum\n",
    "    real_energy = np.mean(np.abs(real_complex)**2, axis=0)\n",
    "    gen_energy = np.mean(np.abs(gen_complex)**2, axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.loglog(wavenumbers, real_energy, 'o-', label='Real Data')\n",
    "    plt.loglog(wavenumbers, gen_energy, 's-', label='Generated Data')\n",
    "    plt.title('Energy Spectrum Comparison')\n",
    "    plt.xlabel('Wavenumber')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    save_path = \"/home/vale/SABRA/params_bin/RBM_figures\"  # Specify the directory to save the figure\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    plt.savefig(os.path.join(save_path, f\"energy_spectrum_comparison_hidden{rbm.h_bias.shape[0]}_visible{rbm.v_bias.shape[0]}_wd{rbm.weight_decay}_batch{batch_size}_k{rbm.k}.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Compare PDFs of real and imaginary parts for a few selected shells\n",
    "    shells_to_plot = [0, len(wavenumbers)//2, -1]  # First, middle, last\n",
    "    \n",
    "    fig, axes = plt.subplots(len(shells_to_plot), 2, figsize=(12, 4*len(shells_to_plot)))\n",
    "    if len(shells_to_plot) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, shell_idx in enumerate(shells_to_plot):\n",
    "        # Real part PDF\n",
    "        axes[i, 0].hist(real_data_np[:, 2*shell_idx], bins=30, alpha=0.5, density=True, label='Real Data')\n",
    "        axes[i, 0].hist(generated_samples[:, 2*shell_idx], bins=30, alpha=0.5, density=True, label='Generated')\n",
    "        axes[i, 0].set_title(f'Shell k={wavenumbers[shell_idx]:.1e} - Real Part')\n",
    "        axes[i, 0].legend()\n",
    "        axes[i, 0].grid(True)\n",
    "        \n",
    "        # Imaginary part PDF\n",
    "        axes[i, 1].hist(real_data_np[:, 2*shell_idx+1], bins=30, alpha=0.5, density=True, label='Real Data')\n",
    "        axes[i, 1].hist(generated_samples[:, 2*shell_idx+1], bins=30, alpha=0.5, density=True, label='Generated')\n",
    "        axes[i, 1].set_title(f'Shell k={wavenumbers[shell_idx]:.1e} - Imaginary Part')\n",
    "        axes[i, 1].legend()\n",
    "        axes[i, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = \"/home/vale/SABRA/params_bin/RBM_figures\"  # Specify the directory to save the figure\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    plt.savefig(os.path.join(save_path, f\"velocity_distribution_comparison_hidden{rbm.h_bias.shape[0]}_visible{rbm.v_bias.shape[0]}_wd{rbm.weight_decay}_batch{batch_size}_k{rbm.k}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the RBM analysis on SABRA model data.\"\"\"\n",
    "    # Configuration\n",
    "    data_dir = \"/home/vale/SABRA/params_bin/sim_nn10_LAM_2_nu1e8/Spectra_complex\"\n",
    "    max_files = 10000\n",
    "    batch_size = 100\n",
    "    num_epochs = 200\n",
    "    n_hidden = 10\n",
    "    normalize = True\n",
    "    weight_decay = 1e-4\n",
    "    k=3\n",
    "    \n",
    "    # Load multiple snapshots\n",
    "    print(f\"Loading data from directory: {data_dir}\")\n",
    "    try:\n",
    "        wavenumbers, velocities = load_multiple_snapshots(data_dir, pattern=\"spectr_complex.*\\.txt\", max_files=max_files)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loaded {velocities.shape[0]} snapshots with {velocities.shape[1]} shells each.\")\n",
    "    \n",
    "    # Prepare data for RBM\n",
    "    data, scalers = prepare_data_for_rbm(velocities, normalize=normalize)\n",
    "    print(f\"scalers: {scalers}\")\n",
    "    \n",
    "    # Initialize RBM\n",
    "    n_visible = 2 * len(wavenumbers)\n",
    "    print(f\"Initializing RBM with {n_visible} visible units and {n_hidden} hidden units\")\n",
    "    \n",
    "    # Create RBM\n",
    "    rbm = ComplexRBM(n_visible=n_visible, \n",
    "                     n_hidden=n_hidden, \n",
    "                     k=k,\n",
    "                     learning_rate=0.01, \n",
    "                     momentum=0.5, \n",
    "                     weight_decay=weight_decay)\n",
    "    \n",
    "    # Train the RBM\n",
    "    print(\"Training RBM...\")\n",
    "\n",
    "    #rbm.load_state_dict(torch.load(\"trained_rbm.pt\"))\n",
    "\n",
    "    rbm = train_rbm(rbm, data, batch_size=batch_size, num_epochs=num_epochs,k=rbm.k,normalize=normalize,)\n",
    "    \n",
    "    # Save trained model\n",
    "    save_path = \"RBMs\"\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    model_filename = f\"trained_rbm_hidden{rbm.h_bias.shape[0]}_visible{rbm.v_bias.shape[0]}_wd{rbm.weight_decay}_batch{batch_size}_k{rbm.k}_epochs{num_epochs}.pt\"\n",
    "    torch.save(rbm.state_dict(), os.path.join(save_path, model_filename))\n",
    "    print(f\"RBM training complete. Saved model to '{os.path.join(save_path, model_filename)}'\")\n",
    "    \n",
    "    # Visualize shell interactions\n",
    "    print(\"Visualizing shell interactions...\")\n",
    "    visualize_shell_interactions(rbm, wavenumbers, batch_size=batch_size,k=rbm.k)\n",
    "    \n",
    "    # Generate and analyze samples\n",
    "    print(\"Generating and analyzing samples...\")\n",
    "    analyze_generated_samples(rbm, data, wavenumbers, n_samples=100,batch_size=batch_size,k=rbm.k)\n",
    "    \n",
    "    # Additional analysis of the learned features\n",
    "    with torch.no_grad():\n",
    "        h_probs = torch.sigmoid(torch.matmul(data, rbm.W) + rbm.h_bias)\n",
    "    \n",
    "    # Save feature representations for further analysis\n",
    "    np.save(\"feature_representations.npy\", h_probs.numpy())\n",
    "    \n",
    "    print(\"Analysis complete. Results saved to disk.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/vale/SABRA/params_bin/sim_nn20_LAM_2_nu1e8/Spectra_complex\"\n",
    "max_files = 10000\n",
    "batch_size = 100\n",
    "num_epochs = 100\n",
    "wavenumbers, velocities = load_multiple_snapshots(data_dir, pattern=\"spectr_complex.*\\.txt\", max_files=max_files)\n",
    "data, scalers = prepare_data_for_rbm(velocities, normalize=True)\n",
    "# Recreate the model with the same architecture as used for training\n",
    "n_visible = 40  # or whatever was used\n",
    "n_hidden = 200  # or whatever was used\n",
    "\n",
    "rbm = ComplexRBM(n_visible=n_visible, n_hidden=n_hidden)\n",
    "rbm.load_state_dict(torch.load(\"trained_rbm.pt\"))\n",
    "\n",
    "# Now call the analysis function\n",
    "analyze_generated_samples(rbm, data, wavenumbers, n_samples=1000)\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
